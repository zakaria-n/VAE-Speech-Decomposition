{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/t6/hlfm94q93sz7p8x7djsrs8nh0000gp/T/ipykernel_1162/3793406994.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (512, 64, 1)\n",
    "conv_filters=(512, 256, 128, 64, 32)\n",
    "conv_kernels=(3, 3, 3, 3, 3)\n",
    "conv_strides=(2, 2, 2, 2, (2,1))\n",
    "vector_dimension = 64\n",
    "latent_space_dim = vector_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVAE(tf.keras.Model):\n",
    "\n",
    "  def __init__(self, latent_dim):\n",
    "    super(CVAE, self).__init__()\n",
    "    self.latent_dim = latent_dim\n",
    "    self.e1 = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_strides, activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_strides, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_space_dim + latent_space_dim),\n",
    "        ]\n",
    "    )\n",
    "    self.e2 = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=input_shape),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_strides, activation='relu'),\n",
    "            tf.keras.layers.Conv2D(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, activation='relu'),\n",
    "            tf.keras.layers.Flatten(),\n",
    "            # No activation\n",
    "            tf.keras.layers.Dense(latent_space_dim + latent_space_dim),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.encode = tf.keras.layers.concatenate([self.e1, self.e2], axis=1)\n",
    "\n",
    "    self.d1 = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_space_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            #tf.keras.layers.Reshape(target_shape=(7, 7, 32)),  # TODO\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.d2 = tf.keras.Sequential(\n",
    "        [\n",
    "            tf.keras.layers.InputLayer(input_shape=(latent_space_dim,)),\n",
    "            tf.keras.layers.Dense(units=7*7*32, activation=tf.nn.relu),\n",
    "            #tf.keras.layers.Reshape(target_shape=(7, 7, 32)),  # TODO\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same',\n",
    "                activation='relu'),\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same',\n",
    "                activation='relu'),\n",
    "            # No activation\n",
    "            tf.keras.layers.Conv2DTranspose(\n",
    "                filters=conv_filters, kernel_size=conv_kernels, strides=conv_filters, padding='same'),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    self.decoder = tf.keras.layers.concatenate([self.d1, self.d2], axis=1) # combine les layers en paralll√®le,\n",
    "                                                                           # mais pas ce qu'on veut finalement\n",
    "\n",
    "  @tf.function\n",
    "  def sample_z1(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode_z1(eps, apply_sigmoid=True)\n",
    "\n",
    "  @tf.function\n",
    "  def sample_z2(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.decode_z2(eps, apply_sigmoid=True)\n",
    "\n",
    "  @tf.function\n",
    "  def sample(self, eps=None):\n",
    "    if eps is None:\n",
    "      eps = tf.random.normal(shape=(100, self.latent_dim))\n",
    "    return self.sample_z1(), self.sample_z2()\n",
    "\n",
    "  def encode_z1(self, x):\n",
    "    mean, logvar = tf.split(self.e1(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def encode_z2(self, x):\n",
    "    mean, logvar = tf.split(self.e2(x), num_or_size_splits=2, axis=1)\n",
    "    return mean, logvar\n",
    "\n",
    "  def encode(self, x):\n",
    "    return self.encode_z1(x), self.encode_z2(x)\n",
    "\n",
    "  def reparameterize(self, mean, logvar):\n",
    "    eps = tf.random.normal(shape=mean.shape)\n",
    "    return eps * tf.exp(logvar * .5) + mean\n",
    "\n",
    "  def decode_z1(self, z1, apply_sigmoid=False):\n",
    "    logits = self.d1(z1)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  def decode_z2(self, z2, apply_sigmoid=False):\n",
    "    logits = self.d2(z2)\n",
    "    if apply_sigmoid:\n",
    "      probs = tf.sigmoid(logits)\n",
    "      return probs\n",
    "    return logits\n",
    "\n",
    "  def decode(self, z1, z2):\n",
    "    logits1 = self.d1(z1)\n",
    "    logits2 = self.d2(z2)\n",
    "    return logits1 + logits2"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
